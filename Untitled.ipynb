{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cbc69c",
   "metadata": {},
   "outputs": [],
   "source": [
    " def __init__(self):\n",
    "        self.name = \"DQN_player\"\n",
    "        self.epsilon = 1\n",
    "        self.learning_rate = 0.1\n",
    "        self.gamma=0.9\n",
    "        \n",
    "        # 두개의 신경망을 생성\n",
    "        self.main_network = self.make_network()\n",
    "\tself.main_network.load_weights('p1_DQN_0708_main_network.h5')\n",
    "\n",
    "        self.target_network = self.make_network()\n",
    "        # 메인 신경망의 가중치를 타깃 신경망의 가중치로 복사\n",
    "        self.copy_network()\n",
    "        \n",
    "        self.print = False\n",
    "        self.print1 = False\n",
    "        self.count = np.zeros(9)\n",
    "        self.win = np.zeros(9)\n",
    "        self.begin = 0\n",
    "        self.e_trend = []\n",
    "        \n",
    "    # 신경망 생성\n",
    "    def make_network(self):\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=(3,3,2)))\n",
    "        self.model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "        self.model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(256, activation='tanh'))\n",
    "        self.model.add(Dense(128, activation='tanh'))\n",
    "        self.model.add(Dense(64, activation='tanh'))\n",
    "        self.model.add(Dense(9))\n",
    "        print(self.model.summary())\n",
    "             \n",
    "        self.model.compile(optimizer = SGD(lr=0.01), loss = 'mean_squared_error', metrics=['mse'])\n",
    "        \n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d0e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Environment():\n",
    "    def __init__(self):\n",
    "        self.board_a = np.zeros(16)\n",
    "        self.done = False\n",
    "        self.reward = 0\n",
    "        self.print = True\n",
    "\n",
    "    def move(self, p1, p2, player):\n",
    "        if player == 1:\n",
    "            pos = p1.select_action(env, player)\n",
    "        else:\n",
    "            pos = p2.select_action(env, player)\n",
    "        \n",
    "        self.board_a[pos] = player\n",
    "\n",
    "        if self.print:\n",
    "            print(player)\n",
    "            self.print_board()\n",
    "\n",
    "        self.end_check(player)\n",
    "        \n",
    "        return  self.reward, self.done\n",
    " \n",
    "    def get_action(self):\n",
    "        observation = []\n",
    "        for i in range(16):\n",
    "            if self.board_a[i] == 0:\n",
    "                observation.append(i)\n",
    "        return observation\n",
    "    \n",
    "    def end_check(self,player):\n",
    "        #  0  1  2  3 \n",
    "        #  4  5  6  7\n",
    "        #  8  9 10 11\n",
    "        # 12 13 14 15\n",
    "        end_condition = ((0,1,2,3), (4,5,6,7), (8,9,10,11), (12,13,14,15), (0,4,8,12), (1,5,9,13), (2,6,10,14), (3,7,11,15), (0,5,10,15), (3,6,9,12))\n",
    "\n",
    "        for line in end_condition:\n",
    "            if self.board_a[line[0]] == self.board_a[line[1]] \\\n",
    "                and self.board_a[line[1]] == self.board_a[line[2]] \\\n",
    "                and self.board_a[line[2]] == self.board_a[line[3]] \\\n",
    "                and self.board_a[line[0]] != 0:\n",
    "\n",
    "                self.done = True\n",
    "                self.reward = player\n",
    "                return\n",
    "\n",
    "        observation = self.get_action()\n",
    "\n",
    "        if (len(observation)) == 0:\n",
    "            self.done = True\n",
    "            self.reward = 0            \n",
    "        return\n",
    "        \n",
    "    def print_board(self):\n",
    "        print(\"+----+----+----+----+\")\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                if self.board_a[4*i+j] == 1:\n",
    "                    print(\"|  O\",end=\" \")\n",
    "                elif self.board_a[4*i+j] == -1:\n",
    "                    print(\"|  X\",end=\" \")\n",
    "                else:\n",
    "                    print(\"|   \",end=\" \")\n",
    "            print(\"|\")\n",
    "            print(\"+----+----+----+----+\")   \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import *\n",
    "from keras import metrics\n",
    "from keras.layers import Dense, Flatten, Conv2D\n",
    "from keras.models import load_model\n",
    "from keras_adamw import AdamW\n",
    "import time\n",
    "           \n",
    "np.random.seed(0)\n",
    "\n",
    "p1_DQN = DQN_player_1()\n",
    "p2_DQN = DQN_player_2()\n",
    "\n",
    "print_opt = False\n",
    "p1_DQN.print = print_opt\n",
    "p2_DQN.print = print_opt\n",
    "\n",
    "p1_score = 0\n",
    "p2_score = 0\n",
    "draw_score = 0\n",
    "\n",
    "np.random.seed(j)\n",
    "env = Environment()\n",
    "        \n",
    "for i in range(10000):\n",
    "    player = 1\n",
    "    pos = p1.select_action(env, player)\n",
    "    env.board_a[pos] = player\n",
    "    env.end_check(player)\n",
    "\n",
    "    if env.done == True:\n",
    "        if env.reward == 0:\n",
    "            draw_score += 1\n",
    "            break\n",
    "        else:\n",
    "            p1_score += 1\n",
    "            break\n",
    "\n",
    "    player = -1\n",
    "    pos = p2.select_action(env, player)\n",
    "    env.board_a[pos] = player\n",
    "    env.end_check(player)\n",
    "\n",
    "    if env.done == True:\n",
    "        if env.reward == 0:\n",
    "            draw_score += 1\n",
    "            break\n",
    "        else:\n",
    "            p2_score += 1\n",
    "            break\n",
    "\n",
    "print(\"p1 = {} p2 = {} draw = {}\".format(p1_score, p2_score, draw_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
